# ----------------------------------------------------------------------------------
# Defines Scope, Rules and Actions enabling down & up propagation on Kafka WOrkflow
# ----------------------------------------------------------------------------------
inspectit:
  metrics:
    enabled: false
  instrumentation:
    data:

      # These markers are used with a_entrypoint_check to detect the http entry and exit points
      # and to make sure that they are recorded only once per request
      'kafka_entrypoint_marker':
        down-propagation: JVM_LOCAL

    scopes:
      's_kafka_producer_send':
        type:
          name: 'org.springframework.kafka.core.KafkaTemplate'
        methods:
          - name: 'doSend'

      's_kafka_kafka_listener':
        interfaces:
          - name: 'MessageListener'
            matcher-mode: ENDS_WITH
        methods:
          - name: 'listen'
        advanced:
          instrument-only-inherited-methods: true

      's_schedular_jobs':
        interfaces:
          - name: 'org.quartz.Job'
        methods:
          - name: 'execute'
        advanced:
          instrument-only-inherited-methods: true

    rules:
      'r_schedular_jobs':
        scopes:
          's_schedular_jobs': true
        tracing:
          start-span: true

      'r_kafka_producer_send':
        scopes:
          's_kafka_producer_send': true
        tracing: 
          start-span: true
          name: 'mc-val'
          attributes:
            'kafka.type': 'kafka_producer_type'
        pre-entry:
          'mc-val':
            action: 'a_kafka_producer_send'
          'do_down_propagation':
            action: 'a_kafka_down_propagation'
        entry:
          'kafka_producer_type':
            action: 'a_assign_value'
            constant-input:
              'value': 'produce'


      'r_kafka_kafka_listener':
        include:
          'r_kafka_detect_entry': true
        scopes:
          's_kafka_kafka_listener': true
        tracing: 
          start-span: true
          attributes:
            'kafka.type': 'kafka_listener_type'
        pre-entry:
          'do_up_propagation':
            action: 'a_kafka_up_propagation'
        entry:
          'kafka_listener_type':
            action: 'a_assign_value'
            constant-input:
              'value': 'listener'
      'r_kafka_detect_entry':
        pre-entry:
          'kafka_is_entry':
            action: 'a_entrypoint_check'
            constant-input: 
              'marker': 'kafka_entrypoint_marker'

    actions:
      'a_pc_get_arg_val':
        imports:
          - 'java.lang.String'
        input:
          _arg0: String
        value-body: |
          return _arg0.toString();

      'a_kafka_producer_send':
        imports:
          - 'java.lang'
          - 'java.lang.reflect'
          - 'org.apache.kafka.common.header'
          - 'java.nio.charset'
          - 'org.apache.kafka.clients.producer'
        input:
          _arg0: Object
        value-body: |
            return ((ProducerRecord)_arg0).topic();

      'a_kafka_up_propagation':
        is-void: true
        imports:
          - 'java.lang'
          - 'java.util'
          - 'org.springframework.messaging'
          - 'java.nio.charset'
        input:
          _attachments: 'ObjectAttachments'
          _context: 'InspectitContext'
          _arg1: MessageHeaders
        value-body: |
          Object propagationAlreadyPerformed = _attachments.attach(_arg1, "up_prop_performed", Boolean.TRUE);
          if (propagationAlreadyPerformed == null) {
            Collection headerKeys = _context.getPropagationHeaderNames();
            Map presentHeaders = new HashMap();
            Iterator it = headerKeys.iterator();

            while (it.hasNext()) {
              String name = (String) it.next();
              Object value = _arg1.get(name);
              if (value != null) {
                String headerValue = null;
                if(value instanceof byte[]){
                    headerValue = new String((byte[]) value, StandardCharsets.UTF_8);
                  } else {
                    headerValue =value.toString();
                  }
                  
                  presentHeaders.put(name, headerValue);
              }
            }
            _context.readDownPropagationHeaders(presentHeaders);
          }


      # Writes down-propagated data to the Kafka Headers
      'a_kafka_down_propagation':
        is-void: true
        imports:
          - 'java.util'
          - 'java.net'
          - 'java.lang'
          - 'java.lang.reflect'
          - 'org.apache.kafka.common.header'
          - 'java.nio.charset'
          - 'org.apache.kafka.clients.producer'
        input:
          _attachments: 'ObjectAttachments'
          _context: 'InspectitContext'
          _arg0: Object
          _this: Object
        value-body: |
          Object propagationAlreadyPerformed = _attachments.attach(_arg0, "down_prop_performed", Boolean.TRUE);
          if (propagationAlreadyPerformed == null) {
            try {
              Map headersIt = _context.getDownPropagationHeaders();
              Iterator it = headersIt.entrySet().iterator();
              Headers headers = ((ProducerRecord)_arg0).headers();
              while (it.hasNext()) {
                Object next = it.next();
                Map$Entry e = (Map$Entry) next;
                Object mKey = e.getKey();
                Object mValue = e.getValue();
                headers.add(mKey.toString(), mValue.toString().getBytes(StandardCharsets.UTF_8));
              }

            } catch (Exception ex) {
              // silently ignore, this will occur if the url has already been connected
              // normally does not happen, as we also instrument connect()
              // it can still happen if connect() is instrumented last
            }
          }

